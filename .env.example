# Minimal startup configuration - only Supabase connection required
# All other settings (API keys, model choices, RAG flags) are managed via the Settings page

# =====================================================
# REQUIRED: SUPABASE CONFIGURATION
# =====================================================
# Get your SUPABASE_URL from the Data API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co

# Get your SUPABASE_SERVICE_KEY from the API Keys section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api-keys
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=YOUR_SUPABASE_SERVICE_KEY_HERE

# =====================================================
# TRACEABILITY DATABASE CONFIGURATION
# =====================================================
# Remote PostgreSQL database for traceability and pattern learning
# Uses the omninode-bridge PostgreSQL container on 192.168.86.200
TRACEABILITY_DB_HOST=192.168.86.200
TRACEABILITY_DB_PORT=5436
TRACEABILITY_DB_NAME=omninode_bridge
TRACEABILITY_DB_USER=postgres
TRACEABILITY_DB_PASSWORD=YOUR_DATABASE_PASSWORD_HERE
# Remote bridge services running on 192.168.86.200
TRACEABILITY_DB_URL=postgresql://postgres:YOUR_DATABASE_PASSWORD_HERE@192.168.86.200:5436/omninode_bridge
# Agent logging DB connection (uses same database as traceability)
# Remote connection to bridge services at 192.168.86.200
PG_DSN=postgresql://postgres:YOUR_DATABASE_PASSWORD_HERE@192.168.86.200:5436/omninode_bridge

# External access from host machine (use port 5436)
# TRACEABILITY_DB_HOST_EXTERNAL=localhost
# TRACEABILITY_DB_PORT_EXTERNAL=5436
# TRACEABILITY_DB_URL_EXTERNAL=postgresql://postgres:YOUR_DATABASE_PASSWORD_HERE@localhost:5436/omninode_bridge

# =====================================================
# LOCAL HOSTING CONFIGURATION
# =====================================================
# Service Ports Configuration
# These ports are used for external access to the services
HOST=localhost
ARCHON_SERVER_PORT=8181
ARCHON_MCP_PORT=8051
ARCHON_AGENTS_PORT=8052
ARCHON_UI_PORT=3737
ARCHON_DOCS_PORT=3838
INTELLIGENCE_SERVICE_PORT=8053
BRIDGE_SERVICE_PORT=8054
SEARCH_SERVICE_PORT=8055

# Service URLs Configuration (derived from HOST and ports above)
ARCHON_SERVER_URL=http://localhost:8181
ARCHON_MCP_URL=http://localhost:8051
ARCHON_AGENTS_URL=http://localhost:8052
INTELLIGENCE_SERVICE_URL=http://localhost:8053
BRIDGE_SERVICE_URL=http://192.168.86.200:8054
SEARCH_SERVICE_URL=http://localhost:8055

# =====================================================
# OLLAMA CONFIGURATION
# =====================================================
# Your existing Ollama server configuration
# The system will use this URL for Ollama API calls
# This will be set in the Settings UI after startup, but documented here for reference
# LLM_BASE_URL=http://192.168.86.200:11434/v1

# =====================================================
# VLLM AI PC CONFIGURATION (192.168.86.201)
# =====================================================
# High-performance vLLM endpoints on AI PC (2-5x faster than Ollama)
# DeepSeek-Coder-V2-Lite-Instruct for code generation
VLLM_DEEPSEEK_URL=http://192.168.86.201:8000/v1

# Meta-Llama-3.1-8B-Instruct for test generation and documentation
VLLM_LLAMA_URL=http://192.168.86.201:8001/v1

# =====================================================
# MCP TIMEOUT CONFIGURATION
# =====================================================
# Timeout settings for MCP service HTTP requests
MCP_REQUEST_TIMEOUT=60.0
MCP_CONNECT_TIMEOUT=10.0
MCP_READ_TIMEOUT=45.0
MCP_WRITE_TIMEOUT=15.0

# Bridge sync polling configuration
MCP_POLLING_TIMEOUT=60.0
MCP_POLLING_READ_TIMEOUT=30.0
MCP_MAX_POLLING_ATTEMPTS=30
MCP_POLLING_BASE_INTERVAL=1.0
MCP_POLLING_MAX_INTERVAL=5.0

# =====================================================
# OPTIONAL CONFIGURATION
# =====================================================
# Optional: Set log level for debugging
LOGFIRE_TOKEN=
LOG_LEVEL=INFO

# AI Model API Keys
# Google Gemini API key for cloud-based inference (copied from omnibase_3)
GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY_HERE
GEMINI_API_KEY=YOUR_GEMINI_API_KEY_HERE

# Z.AI API key for GLM-4.6 inference (add your key here after subscribing)
Z_AI_API_KEY=YOUR_Z_AI_API_KEY_HERE
Z_AI_API_URL=https://api.z.ai/api/coding/paas/v4

# Embedding Configuration
# Dimensions for embedding vectors (768 for nomic-embed-text, 1024 for mxbai-embed-large)
# Set to 768 since nomic-embed-text is recommended for Ollama
EMBEDDING_DIMENSIONS=768

# NOTE: All other configuration has been moved to database management!
# Run the complete_setup.sql file in your Supabase SQL editor to set up the credentials table.
# Then use the Settings page in the web UI to manage:
# - LLM Provider: Set to "ollama"
# - LLM_BASE_URL: http://192.168.86.200:11434/v1
# - EMBEDDING_MODEL: Choose appropriate Ollama embedding model (e.g., nomic-embed-text)
# - MODEL_CHOICE: Choose your preferred Ollama model
# - RAG strategy flags (USE_CONTEXTUAL_EMBEDDINGS, USE_HYBRID_SEARCH, etc.)
SERVICE_AUTH_TOKEN=YOUR_SERVICE_AUTH_TOKEN_HERE

# OpenAI API Key for embeddings (currently using dummy - switch to Ollama or add real key)
OPENAI_API_KEY=sk-dummy-key-replace-with-real-or-use-ollama

# =====================================================
# VALKEY CACHE SECURITY CONFIGURATION
# =====================================================
# Password for Valkey (Redis fork) distributed cache
# IMPORTANT: Change this in production deployments!
VALKEY_PASSWORD=YOUR_VALKEY_PASSWORD_HERE
VALKEY_URL=redis://:YOUR_VALKEY_PASSWORD_HERE@archon-valkey:6379/0
GH_PAT=YOUR_GITHUB_PERSONAL_ACCESS_TOKEN_HERE

# =====================================================
# EXTERNAL MCP GATEWAY CONFIGURATION
# =====================================================
# Enable external MCP service integration (zen, codanna, serena, etc.)
ARCHON_ENABLE_EXTERNAL_GATEWAY=true

# =====================================================
# KAFKA/REDPANDA CONFIGURATION
# =====================================================
# Remote Redpanda broker on 192.168.86.200
# Port 9092: Direct connection to Redpanda (updated 2025-10-27)
# See docs/KAFKA_PORT_CONFIGURATION.md for details

KAFKA_BROKERS=192.168.86.200:9092

# Legacy/compatibility (use KAFKA_BROKERS instead)
KAFKA_BOOTSTRAP_SERVERS=192.168.86.200:9092

# Kafka topics
KAFKA_DOC_TOPIC=dev.omniclaude.docs.evt.documentation-changed.v1

# Feature flags
ENABLE_EVENT_INTELLIGENCE=true
ENABLE_KAFKA_LOGGING=true
ENABLE_REAL_TIME_EVENTS=true

# Performance tuning (milliseconds)
KAFKA_REQUEST_TIMEOUT_MS=5000
KAFKA_PATTERN_DISCOVERY_TIMEOUT_MS=5000
KAFKA_CODE_ANALYSIS_TIMEOUT_MS=10000
KAFKA_QUALITY_ASSESSMENT_TIMEOUT_MS=10000

# =====================================================
# OMNIDASH POSTGRES CONFIGURATION
# =====================================================
# These variables are used by omnidash server/storage.ts
# They point to the same database as TRACEABILITY_DB_* above
POSTGRES_HOST=192.168.86.200
POSTGRES_PORT=5436
POSTGRES_DATABASE=omninode_bridge
POSTGRES_USER=postgres
POSTGRES_PASSWORD=YOUR_DATABASE_PASSWORD_HERE

PORT=3000
